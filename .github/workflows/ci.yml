---
name: CI

on:
  push: {}
  pull_request: {}
  merge_group: {}
  workflow_dispatch: {}

# Limit workflow to 1 concurrent run per ref (branch): new commit -> old runs are canceled to save costs
# Exception for main branch: complete builds for every commit needed for confidenence
# Exception for deploy jobs that have to wait for each other to avoid overwriting
concurrency:
  cancel-in-progress: true
  group: ${{ format('{0}-{1}', github.workflow, github.ref == 'refs/heads/main' && github.sha || github.ref) }}

defaults:
  run:
    # use bash shell by default to ensure pipefail behavior is the default
    # see https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#exit-codes-and-error-action-preference
    shell: bash

env:
  DOCKER_PLATFORMS: "linux/amd64,linux/arm64"

jobs:
  java-unit-tests:
    runs-on: gcp-perf-core-16-default
    timeout-minutes: 120
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/setup-zeebe
        with:
          secret_vault_secretId: ${{ secrets.VAULT_SECRET_ID }}
          secret_vault_address: ${{ secrets.VAULT_ADDR }}
          secret_vault_roleId: ${{ secrets.VAULT_ROLE_ID }}
      - run: |
          tail -f /dev/null
      # - uses: ./.github/actions/build-zeebe
      #   with:
      #     maven-extra-args: -T1C -PskipFrontendBuild -D skipOptimize
      # - name: Create build output log file
      #   run: echo "BUILD_OUTPUT_FILE_PATH=$(mktemp)" >> $GITHUB_ENV
      # - name: Maven Test Build
      #   # we use the verify goal here as flaky test extraction is bound to the post-integration-test
      #   # phase of Maven https://maven.apache.org/guides/introduction/introduction-to-the-lifecycle.html#default-lifecycle
      #   run: >
      #     ./mvnw -T2 -B --no-snapshot-updates
      #     -D skipITs -D skipQaBuild=true -D skipChecks -D surefire.rerunFailingTestsCount=3
      #     -D junitThreadCount=16
      #     -D skipOptimize
      #     -P skip-random-tests,parallel-tests,extract-flaky-tests,skipFrontendBuild
      #     verify
      #     | tee "${BUILD_OUTPUT_FILE_PATH}"
      # - name: Analyze Test Runs
      #   id: analyze-test-run
      #   if: always()
      #   uses: ./.github/actions/analyze-test-runs
      #   with:
      #     buildOutputFilePath: ${{ env.BUILD_OUTPUT_FILE_PATH }}
      # - name: Upload test artifacts
      #   uses: ./.github/actions/collect-test-artifacts
      #   if: ${{ failure() || cancelled() }}
      #   with:
      #     name: "unit tests"
      # - name: Observe build status
      #   if: always()
      #   continue-on-error: true
      #   uses: ./.github/actions/observe-build-status
      #   with:
      #     build_status: ${{ job.status }}
      #     user_reason: ${{ (steps.analyze-test-run.outputs.flakyTests != '') && 'flaky-tests' || '' }}
      #     user_description: ${{ steps.analyze-test-run.outputs.flakyTests }}
      #     secret_vault_secretId: ${{ secrets.VAULT_SECRET_ID }}
      #     secret_vault_address: ${{ secrets.VAULT_ADDR }}
      #     secret_vault_roleId: ${{ secrets.VAULT_ROLE_ID }}

